{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-05T23:30:23.572559",
     "start_time": "2016-05-05T23:30:22.580423"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# theano imports\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "# from theano.tensor.signal.downsample import max_pool_2d\n",
    "from theano.tensor.signal.pool import pool_2d as max_pool_2d\n",
    "from theano.tensor.nnet import batch_normalization\n",
    "\n",
    "# other imports\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-05T23:30:23.661653",
     "start_time": "2016-05-05T23:30:23.574099"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def glorot_init_weights(shape):\n",
    "    (h, w) = shape\n",
    "    # 0.25 for sigmoid, 0.1 for softmax, 1.0 for tanh/relu\n",
    "    normalizer = 2.0 * (6**0.5) / ((h + w)**0.5) * 1.0  #factors: 0.1 correct for uni[0,1], glo, glo, softmax deriv\n",
    "    return theano.shared(floatX((np.random.random_sample(shape) - 0.5) * normalizer))\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "def activate(X):\n",
    "    return T.nnet.relu(X)\n",
    "\n",
    "def rectify(X):\n",
    "#     return T.maximum(X, 0.)\n",
    "    return T.maximum(X, 0.01*X)  #leaky rectifier\n",
    "\n",
    "def ELU(X, alpha=0.1):\n",
    "    return T.switch(X > 0, X, alpha * (T.exp(X) - 1))\n",
    "    \n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 1, 'x', 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 1, 'x', 'x')\n",
    "\n",
    "def dropout(X, p=0.0):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    \n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    \n",
    "    return updates\n",
    "\n",
    "# data, input weights, gamma input, beta input, hidden weights, hidden bias, gamma hidden, beta hidden, \n",
    "# output weights, output bias, gamma output, beta output, p_drop, p_hidden_drop\n",
    "def model(X, wi, gi, bbi, wh, bh, gh, bbh, wo, bo, go, bbo, p_drop_conv, p_drop_hidden):\n",
    "\n",
    "    # --------------------------------------------\n",
    "    \n",
    "    layer_1 = conv2d(X, wi, border_mode='valid')\n",
    "    layer_1 = layer_1.reshape((-1, 256))\n",
    "    layer_1 = batch_normalization(layer_1, gamma=gi, beta=bbi, \n",
    "                                 mean=X.mean((0, ), keepdims=True), \n",
    "                                  std = T.ones_like(X.var((0,), keepdims=True)), \n",
    "                                  mode='high_mem')\n",
    "    layer_1 = dropout(layer_1, p_drop_conv)\n",
    "\n",
    "    # --------------------------------------------\n",
    "    \n",
    "    layer_2 = T.dot(layer_1, wh) + bh\n",
    "    layer_2 = batch_normalization(layer_2, gamma=gh, beta=bbh, \n",
    "                                 mean=X.mean((0, ), keepdims=True), \n",
    "                                  std = T.ones_like(layer_2.var((0,), keepdims=True)), \n",
    "                                  mode='high_mem')\n",
    "    \n",
    "    layer_2 = rectify(layer_2)\n",
    "    layer_2 = dropout(layer_2, p_drop_hidden)\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    \n",
    "    layer_3 = T.dot(layer_2, wo) + bo\n",
    "    layer_3 = batch_normalization(layer_3, gamma=go, beta=bbo, \n",
    "                                 mean=X.mean((0, ), keepdims=True), \n",
    "                                  std = T.ones_like(layer_3.var((0,), keepdims=True)), \n",
    "                                  mode='high_mem')\n",
    "    \n",
    "    layer_3 = dropout(layer_3, p_drop_hidden)\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    \n",
    "#     pyx = softmax(T.dot(layer_2, wo))\n",
    "    pyx = T.nnet.softmax(layer_3)\n",
    "    return layer_1, layer_2, layer_3, pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-05T23:30:24.226697",
     "start_time": "2016-05-05T23:30:24.206169"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define mini-batch size\n",
    "mbs = 128\n",
    "\n",
    "# define number of desired features out of convolution\n",
    "n_conv = 256\n",
    "\n",
    "# define hidden layer depth\n",
    "h_depth = 600\n",
    "\n",
    "# define output layer size\n",
    "o_depth = 6\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# initialize weight matrices: wi, gi, bbi, wh, bh, gh, bbh, wo, bo, go, bbo\n",
    "\n",
    "# input parameters\n",
    "wi = np.random.rand((n_conv, 1, 13, 21))\n",
    "gi = floatX(np.ones(n_conv)))\n",
    "bbi = theano.shared(floatX(np.zeros(n_conv)))\n",
    "\n",
    "# hidden parameters\n",
    "wh = glorot_init_weights((n_conv, h_depth))\n",
    "bh = theano.shared(floatX(np.zeros(h_depth)))\n",
    "gh = theano.shared(floatX(np.ones(h_depth)))\n",
    "bbh = theano.shared(floatX(np.zeros(h_depth)))\n",
    "\n",
    "# output parameters\n",
    "wo = glorot_init_weights((h_depth, o_depth))\n",
    "bo = theano.shared(floatX(np.zeros(o_depth)))\n",
    "go = theano.shared(floatX(np.ones(o_depth)))\n",
    "bbo = theano.shared(floatX(np.zeros(o_depth)))\n",
    "\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-05T23:30:28.019340",
     "start_time": "2016-05-05T23:30:28.014370"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorType(float32, 4D)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
