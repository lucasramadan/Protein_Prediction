{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:51:55.634572",
     "start_time": "2016-05-07T15:51:26.918429"
    },
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# theano imports\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "# from theano.tensor.signal.downsample import max_pool_2d\n",
    "from theano.tensor.signal.pool import pool_2d as max_pool_2d\n",
    "from theano.tensor.nnet import batch_normalization\n",
    "\n",
    "# other imports\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:51:55.642027",
     "start_time": "2016-05-07T15:51:55.636942"
    },
    "collapsed": true,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting our data in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:51:55.655009",
     "start_time": "2016-05-07T15:51:55.645549"
    },
    "collapsed": true,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# helper function for loading in data of a specific encoding window\n",
    "def get_data_tensor(n = 5):\n",
    "    filename = 'conv_data/' + str(n) + '_tensor.p'\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    \n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:52:10.364657",
     "start_time": "2016-05-07T15:51:55.658841"
    },
    "collapsed": true,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# read our data in \n",
    "\n",
    "n_window = 13\n",
    "n_aminos = 21\n",
    "\n",
    "loaded_data = get_data_tensor(n = n_window)\n",
    "    \n",
    "labels = pd.read_csv('one_hot_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:52:10.413345",
     "start_time": "2016-05-07T15:52:10.373908"
    },
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data[:2]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:52:10.420517",
     "start_time": "2016-05-07T15:52:10.417166"
    },
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "one_hot = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:52:10.431572",
     "start_time": "2016-05-07T15:52:10.422657"
    },
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:52:10.439859",
     "start_time": "2016-05-07T15:52:10.434840"
    },
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# # trying to scale data\n",
    "# sc = StandardScaler()\n",
    "# sc.fit(loaded_data[0])\n",
    "\n",
    "# # now scale each pt\n",
    "# scaled_data = np.asarray([sc.transform(d) for d in loaded_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:52:10.789893",
     "start_time": "2016-05-07T15:52:10.441941"
    },
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(loaded_data, one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:52:10.801611",
     "start_time": "2016-05-07T15:52:10.793395"
    },
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101110, 13, 21) (33704, 13, 21) (101110, 6) (33704, 6)\n"
     ]
    }
   ],
   "source": [
    "print xTrain.shape, xTest.shape, yTrain.shape, yTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:52:10.811755",
     "start_time": "2016-05-07T15:52:10.806139"
    },
    "collapsed": true,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "xTrain = xTrain.reshape(-1, 1, n_window, n_aminos)\n",
    "xTest = xTest.reshape(-1, 1, n_window, n_aminos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:52:10.829871",
     "start_time": "2016-05-07T15:52:10.821809"
    },
    "collapsed": false,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101110, 1, 13, 21) (33704, 1, 13, 21) (101110, 6) (33704, 6)\n"
     ]
    }
   ],
   "source": [
    "print xTrain.shape, xTest.shape, yTrain.shape, yTest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now time to declare some Theano functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:52:22.104239",
     "start_time": "2016-05-07T15:52:21.986142"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def glorot_init_weights(shape):\n",
    "    (h, w) = shape\n",
    "    # 0.25 for sigmoid, 0.1 for softmax, 1.0 for tanh/relu\n",
    "    normalizer = 2.0 * (6**0.5) / ((h + w)**0.5) * 1.0  #factors: 0.1 correct for uni[0,1], glo, glo, softmax deriv\n",
    "    return theano.shared(floatX((np.random.random_sample(shape) - 0.5) * normalizer))\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "def activate(X):\n",
    "    return T.nnet.relu(X)\n",
    "\n",
    "def rectify(X):\n",
    "#     return T.maximum(X, 0.)\n",
    "    return T.maximum(X, 0.01*X)  #leaky rectifier\n",
    "\n",
    "def ELU(X, alpha=0.1):\n",
    "    return T.switch(X > 0, X, alpha * (T.exp(X) - 1))\n",
    "    \n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 1, 'x', 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 1, 'x', 'x')\n",
    "\n",
    "def dropout(X, p=0.0):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    \n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    \n",
    "    return updates\n",
    "\n",
    "def shuffle(x, y):\n",
    "    # helper function to shuffle indicies each loop \n",
    "    index = np.random.choice(len(x), len(x), replace=False)\n",
    "    return x[index], y[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to implement batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:52:29.720737",
     "start_time": "2016-05-07T15:52:29.683155"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# hoping to get batch normalization implemented below\n",
    "# data, input weights, gamma input, beta input, hidden weights, hidden bias, gamma hidden, beta hidden, \n",
    "# output weights, output bias, gamma output, beta output, p_drop, p_hidden_drop\n",
    "def model_bn(X, wi, gi, bbi, wh, bh, gh, bbh, wo, bo, go, bbo, p_drop_conv, p_drop_hidden):\n",
    "\n",
    "    # --------------------------------------------\n",
    "    \n",
    "    layer_1 = conv2d(X, wi, border_mode='valid')\n",
    "    layer_1 = layer_1.reshape((-1, 256))\n",
    "    layer_1 = batch_normalization(layer_1, gamma=gi, beta=bbi, \n",
    "                                 mean=layer_1.mean((1), keepdims=True), \n",
    "                                  std = T.ones_like(layer_1.std((1), keepdims=True)), \n",
    "                                  mode='high_mem')\n",
    "\n",
    "#     layer_1 = dropout(layer_1, p_drop_conv)\n",
    "\n",
    "    # --------------------------------------------\n",
    "    \n",
    "    layer_2 = T.dot(layer_1, wh) + bh\n",
    "#     layer_2 = batch_normalization(layer_2, gamma=gh, beta=bbh, \n",
    "#                                  mean=X.mean((1, ), keepdims=True), \n",
    "#                                   std = T.ones_like(layer_2.var((1,), keepdims=True)), \n",
    "#                                   mode='high_mem')\n",
    "    \n",
    "    layer_2 = activate(layer_2)\n",
    "    layer_2 = dropout(layer_2, p_drop_hidden)\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    \n",
    "    layer_3 = T.dot(layer_2, wo) + bo\n",
    "#     layer_3 = batch_normalization(layer_3, gamma=go, beta=bbo, \n",
    "#                                  mean=X.mean((1, ), keepdims=True), \n",
    "#                                   std = T.ones_like(layer_3.var((1,), keepdims=True)), \n",
    "#                                   mode='high_mem')\n",
    "    \n",
    "    layer_3 = dropout(layer_3, p_drop_hidden)\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    \n",
    "    # thinks it's getting a 4D Tensor ???\n",
    "#     pyx = softmax(layer_3)\n",
    "    pyx = T.nnet.softmax(layer_3)\n",
    "    return layer_1, layer_2, layer_3, pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T15:53:54.019799",
     "start_time": "2016-05-07T15:53:47.019253"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X = T.ftensor4()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "# define mini-batch size\n",
    "mbs = 64\n",
    "\n",
    "# define number of desired features out of convolution\n",
    "n_conv = 256\n",
    "\n",
    "# define hidden layer depth\n",
    "h_depth = 600\n",
    "\n",
    "# define output layer size\n",
    "o_depth = 6\n",
    "\n",
    "# --------------------------- FOR BATCH NORMALIZATION (NOT WORKING) -----------------------\n",
    "\n",
    "# initialize weight matrices: wi, gi, bbi, wh, bh, gh, bbh, wo, bo, go, bbo\n",
    "\n",
    "# input parameters\n",
    "wi = init_weights((n_conv, 1, n_window, n_aminos))\n",
    "gi = theano.shared(floatX(np.ones((mbs, n_conv))))\n",
    "bbi = theano.shared(floatX(np.zeros((mbs, n_conv))))\n",
    "\n",
    "# hidden parameters\n",
    "wh = glorot_init_weights((n_conv, h_depth))\n",
    "bh = theano.shared(floatX(np.zeros(h_depth))) # can remove later\n",
    "gh = theano.shared(floatX(np.ones((mbs, h_depth))))\n",
    "bbh = theano.shared(floatX(np.zeros((mbs, h_depth))))\n",
    "\n",
    "# output parameters\n",
    "wo = glorot_init_weights((h_depth, o_depth))\n",
    "bo = theano.shared(floatX(np.zeros(o_depth)))\n",
    "go = theano.shared(floatX(np.ones((mbs, o_depth))))\n",
    "bbo = theano.shared(floatX(np.zeros((mbs, o_depth))))\n",
    "\n",
    "#modeling and parameters for Gradient Descent\n",
    "noise_l1, noise_l2, noise_l3, noise_py_x = model_bn(X, wi, gi, bbi, wh, bh, gh, bbh, wo, bo, go, bbo, 0.2, 0.5)\n",
    "l1, l2, l3, py_x = model_bn(X, wi, gi, bbi, wh, bh, gh, bbh, wo, bo, go, bbo, 0., 0.)\n",
    "# params = [wi, gi, bbi, wh, bh, gh, bbh, wo, bo, go, bbo]\n",
    "\n",
    "params = [wi, gi, bbi, wh, bh, wo, bo]\n",
    "\n",
    "# --------------------------- FOR BATCH NORMALIZATION (NOT WORKING) -----------------------\n",
    "\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "updates = RMSprop(cost, \n",
    "                  params, \n",
    "                  lr=1e-4) #lr=1e-7 <--- way too small of a LR\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-06T18:19:06.457359",
     "start_time": "2016-05-06T17:26:27.862573"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1     Test: 0.71875        Train: 0.703125\n",
      "Round: 2     Test: 0.625          Train: 0.59375 \n",
      "Round: 3     Test: 0.609375       Train: 0.59375 \n",
      "Round: 4     Test: 0.53125        Train: 0.546875\n",
      "Round: 5     Test: 0.65625        Train: 0.703125\n",
      "Round: 6     Test: 0.484375       Train: 0.71875 \n",
      "Round: 7     Test: 0.671875       Train: 0.546875\n",
      "Round: 8     Test: 0.5            Train: 0.65625 \n",
      "Round: 9     Test: 0.5625         Train: 0.71875 \n",
      "Round: 10    Test: 0.6875         Train: 0.71875 \n",
      "Round: 11    Test: 0.640625       Train: 0.609375\n",
      "Round: 12    Test: 0.625          Train: 0.78125 \n",
      "Round: 13    Test: 0.65625        Train: 0.59375 \n",
      "Round: 14    Test: 0.71875        Train: 0.6875  \n",
      "Round: 15    Test: 0.59375        Train: 0.703125\n",
      "Round: 16    Test: 0.53125        Train: 0.703125\n",
      "Round: 17    Test: 0.65625        Train: 0.59375 \n",
      "Round: 18    Test: 0.6875         Train: 0.5625  \n",
      "Round: 19    Test: 0.71875        Train: 0.640625\n",
      "Round: 20    Test: 0.71875        Train: 0.640625\n",
      "Round: 21    Test: 0.75           Train: 0.65625 \n",
      "Round: 22    Test: 0.609375       Train: 0.703125\n",
      "Round: 23    Test: 0.671875       Train: 0.6875  \n",
      "Round: 24    Test: 0.640625       Train: 0.640625\n",
      "Round: 25    Test: 0.609375       Train: 0.703125\n",
      "Round: 26    Test: 0.65625        Train: 0.6875  \n",
      "Round: 27    Test: 0.6875         Train: 0.71875 \n",
      "Round: 28    Test: 0.71875        Train: 0.59375 \n",
      "Round: 29    Test: 0.78125        Train: 0.6875  \n",
      "Round: 30    Test: 0.71875        Train: 0.671875\n",
      "Round: 31    Test: 0.609375       Train: 0.703125\n",
      "Round: 32    Test: 0.75           Train: 0.546875\n",
      "Round: 33    Test: 0.71875        Train: 0.609375\n",
      "Round: 34    Test: 0.6875         Train: 0.6875  \n",
      "Round: 35    Test: 0.78125        Train: 0.765625\n",
      "Round: 36    Test: 0.78125        Train: 0.78125 \n",
      "Round: 37    Test: 0.640625       Train: 0.671875\n",
      "Round: 38    Test: 0.625          Train: 0.671875\n",
      "Round: 39    Test: 0.609375       Train: 0.71875 \n",
      "Round: 40    Test: 0.609375       Train: 0.78125 \n",
      "Round: 41    Test: 0.625          Train: 0.6875  \n",
      "Round: 42    Test: 0.640625       Train: 0.765625\n",
      "Round: 43    Test: 0.640625       Train: 0.734375\n",
      "Round: 44    Test: 0.6875         Train: 0.71875 \n",
      "Round: 45    Test: 0.71875        Train: 0.8125  \n",
      "Round: 46    Test: 0.6875         Train: 0.765625\n",
      "Round: 47    Test: 0.625          Train: 0.734375\n",
      "Round: 48    Test: 0.71875        Train: 0.703125\n",
      "Round: 49    Test: 0.609375       Train: 0.8125  \n",
      "Round: 50    Test: 0.6875         Train: 0.875   \n",
      "Round: 51    Test: 0.625          Train: 0.640625\n",
      "Round: 52    Test: 0.5625         Train: 0.828125\n",
      "Round: 53    Test: 0.765625       Train: 0.75    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-11b3dd4d6f3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTrainbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#             index = np.random.choice(xTrain.shape[0], batch_size, replace=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mt_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# number of training iterations to perform\n",
    "n_train = 31\n",
    "\n",
    "# store our results\n",
    "costs = []\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "\n",
    "# borrowing some mini-batching for\n",
    "\n",
    "Trainbatches = zip(range(0, len(xTrain), mbs), range(mbs, len(xTrain), mbs))\n",
    "Testbatches  = zip(range(0, len(xTest), mbs), range(mbs, len(xTest), mbs))\n",
    "y_codes      = np.argmax(yTest, axis=1)\n",
    "\n",
    "t_start = time.time()\n",
    "t_end = t_start + 60 * 100\n",
    "count = 1\n",
    "\n",
    "\n",
    "while time.time() < t_end:\n",
    "\n",
    "    for start, end in Trainbatches:\n",
    "#             index = np.random.choice(xTrain.shape[0], batch_size, replace=False)\n",
    "        cost = train(xTrain[start:end], yTrain[start:end])\n",
    "        if time.time() > t_end:\n",
    "            break\n",
    "\n",
    "\n",
    "    xTrain, yTrain = shuffle(xTrain, yTrain)\n",
    "    xTest, yTest   = shuffle(xTest, yTest)\n",
    "\n",
    "\n",
    "    tr, trr = [], []\n",
    "    \n",
    "    for start, end in Testbatches:    \n",
    "        tr  = [np.mean(np.argmax(yTest[start:end], axis=1) == predict(xTest[start:end]))]\n",
    "        trr = [np.mean(np.argmax(yTrain[start:end], axis=1) == predict(xTrain[start:end]))]\n",
    "    print \"Round: %-5s Test: %-14s Train: %-8s\" % (count, np.mean(tr), np.mean(trr))\n",
    "\n",
    "#     if count == 15:\n",
    "#         cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "#         params = [w, w2, w3, w4, w_o]\n",
    "#         updates = RMSprop(cost, params, lr=0.0001)\n",
    "\n",
    "#         train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, \n",
    "#                                 allow_input_downcast=True)\n",
    "\n",
    "#         predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "\n",
    "    count += 1\n",
    "\n",
    "print \"Time:\",  round(((time.time() - t_start)/60.0), 2), 'minutes'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-06T18:22:52.503018",
     "start_time": "2016-05-06T18:22:52.498187"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(xrange(n_train), train_scores, label='train')\n",
    "plt.plot(xrange(n_train), test_scores, label='test')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-06T18:22:42.644572",
     "start_time": "2016-05-07T01:22:42.634Z"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# plot our results\n",
    "plt.plot(xrange(n_train), costs)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Cost');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-06T00:16:56.232769",
     "start_time": "2016-05-06T00:16:54.740096"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# AMINO MAPS (n_window, 21)\n",
    "aminos = ['-','A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "# positions = ['-1', '-2', '0', '1', '2']\n",
    "\n",
    "positions = sorted(map(str, range(-(n_window-1)//2, (n_window+1)//2, 1)))\n",
    "\n",
    "for conv in wi.eval()[:5]:\n",
    "    c = conv.reshape(n_window, n_aminos)\n",
    "    plt.imshow(c, cmap='Greys')\n",
    "    plt.xticks(range(len(aminos)), aminos)\n",
    "    plt.yticks(range(len(positions)), positions)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#tensor.nnet.softmax\n",
    "http://deeplearning.net/software/theano/library/tensor/nnet/conv.html#theano.tensor.nnet.conv.conv2d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
