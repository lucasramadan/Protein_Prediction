{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Fold-State of Proteins \n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T16:33:17.349447",
     "start_time": "2016-05-07T16:33:17.345310"
    },
    "collapsed": true,
    "hide_input": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T10:57:57.404622",
     "start_time": "2016-05-09T10:57:57.307311"
    },
    "collapsed": false,
    "hide_input": false,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do we care about modeling fold state?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"Screen Shot 2016-05-08 at 10.17.03 PM.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### What a protein looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"85262_large.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T10:57:57.547967",
     "start_time": "2016-05-09T10:57:57.408478"
    },
    "collapsed": true,
    "hide_input": false,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "seq = pd.read_csv('sequences.csv').drop('Unnamed: 0', axis=1).values.reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the protein is encoded for us:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"AA_code.png\" height=400 width=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"protein_seq.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What our actual data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T16:01:15.236278",
     "start_time": "2016-05-07T16:01:15.231569"
    },
    "collapsed": false,
    "hide_input": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V' 'L' 'S' 'P' 'A' 'D' 'K' 'T' 'N' 'V' 'K' 'A' 'A' 'W' 'G' 'K' 'V' 'G'\n",
      " 'A' 'H' 'A' 'G' 'E' 'Y' 'G' 'A' 'E' 'A' 'L' 'E' 'R' 'M' 'F' 'L' 'S' 'F'\n",
      " 'P' 'T' 'T' 'K' 'T' 'Y' 'F' 'P' 'H' 'F' 'D' 'L' 'S' 'H' 'G' 'S' 'A' 'Q'\n",
      " 'V' 'K' 'G' 'H' 'G' 'K' 'K' 'V' 'A' 'D' 'A' 'L' 'T' 'N' 'A' 'V' 'A' 'H'\n",
      " 'V' 'D' 'D' 'M' 'P' 'N' 'A' 'L' 'S' 'A' 'L' 'S' 'D' 'L' 'H' 'A' 'H' 'K'\n",
      " 'L' 'R' 'V' 'D' 'P' 'V' 'N' 'F' 'K' 'L']\n"
     ]
    }
   ],
   "source": [
    "print seq[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How this relates to Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"figure1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"proteins-and-amino-acids-32-638.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fold States:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T17:34:55.186248",
     "start_time": "2016-05-07T17:34:55.125465"
    },
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('5_formatted_labels.csv').drop('Unnamed: 0', axis=1).values.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T17:35:19.446862",
     "start_time": "2016-05-07T17:35:19.442856"
    },
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "fold_map = dict(zip(range(6), [\"H\", \"E\", \"T\", \"S\", \"B\", \"U\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T17:35:21.119326",
     "start_time": "2016-05-07T17:35:21.020757"
    },
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "folds = np.asarray([fold_map[state] for state in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T17:35:21.748563",
     "start_time": "2016-05-07T17:35:21.743138"
    },
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U' 'U' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'U' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'U' 'T' 'T' 'S' 'U' 'U' 'S' 'T' 'T' 'U' 'H' 'H' 'H'\n",
      " 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'T' 'T'\n",
      " 'T' 'S' 'H' 'H' 'H' 'H' 'T' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'H' 'T' 'T'\n",
      " 'U' 'U' 'U' 'T' 'H' 'H' 'H' 'H' 'H' 'H']\n"
     ]
    }
   ],
   "source": [
    "print folds[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T16:41:23.057494",
     "start_time": "2016-05-07T16:41:22.977249"
    },
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold</th>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>V</td>\n",
       "      <td>L</td>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>K</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "      <td>...</td>\n",
       "      <td>L</td>\n",
       "      <td>R</td>\n",
       "      <td>V</td>\n",
       "      <td>D</td>\n",
       "      <td>P</td>\n",
       "      <td>V</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>K</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   ...                              \n",
       "Fold  U  U  H  H  H  H  H  H  H  H ...  U  U  U  T  H  H  H  H  H  H\n",
       "AA    V  L  S  P  A  D  K  T  N  V ...  L  R  V  D  P  V  N  F  K  L\n",
       "\n",
       "[2 rows x 100 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([folds[:100], seq[:100]], index=['Fold', 'AA'], columns=['']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T16:38:46.980375",
     "start_time": "2016-05-07T16:38:46.858344"
    },
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "counts = Counter(folds)\n",
    "percents = [v*1.0 / sum(counts.values()) for v in counts.values()]\n",
    "\n",
    "perc = dict(zip(counts.keys(), percents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T16:38:51.038873",
     "start_time": "2016-05-07T16:38:50.749242"
    },
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEDCAYAAAA7jc+ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nR9ADgOEIegAwHEEPAIb7/w96fKOKNS+jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c1eaa10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(perc)), perc.values(), tick_label=perc.keys(), align='center')\n",
    "sns.set_style('white')\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"cbow.png\" height=400 width=400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How our data is really formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T17:02:23.016432",
     "start_time": "2016-05-07T17:02:20.338881"
    },
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A-2</th>\n",
       "      <th>C-2</th>\n",
       "      <th>D-2</th>\n",
       "      <th>E-2</th>\n",
       "      <th>F-2</th>\n",
       "      <th>G-2</th>\n",
       "      <th>H-2</th>\n",
       "      <th>I-2</th>\n",
       "      <th>K-2</th>\n",
       "      <th>L-2</th>\n",
       "      <th>...</th>\n",
       "      <th>N2</th>\n",
       "      <th>P2</th>\n",
       "      <th>Q2</th>\n",
       "      <th>R2</th>\n",
       "      <th>S2</th>\n",
       "      <th>T2</th>\n",
       "      <th>V2</th>\n",
       "      <th>W2</th>\n",
       "      <th>Y2</th>\n",
       "      <th>-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A-2  C-2  D-2  E-2  F-2  G-2  H-2  I-2  K-2  L-2 ...    N2   P2   Q2   R2  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  1.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "    S2   T2   V2   W2   Y2   -2  \n",
       "0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_data = pd.read_csv('5_formatted_fixed.csv').drop('Unnamed: 0', axis=1)\n",
    "skip_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take for an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T17:02:58.335989",
     "start_time": "2016-05-07T17:02:58.330108"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V' 'L' 'S' 'P' 'A']\n"
     ]
    }
   ],
   "source": [
    "print seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T17:04:25.685017",
     "start_time": "2016-05-07T17:04:25.678619"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V-2', 'L-1', 'S0', 'P1', 'A2']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['V-2', 'L-1', 'S0', 'P1', 'A2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T17:17:30.802335",
     "start_time": "2016-05-07T17:17:30.725530"
    },
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>A-2</td>\n",
       "      <td>C-2</td>\n",
       "      <td>D-2</td>\n",
       "      <td>E-2</td>\n",
       "      <td>F-2</td>\n",
       "      <td>G-2</td>\n",
       "      <td>H-2</td>\n",
       "      <td>I-2</td>\n",
       "      <td>K-2</td>\n",
       "      <td>L-2</td>\n",
       "      <td>...</td>\n",
       "      <td>N2</td>\n",
       "      <td>P2</td>\n",
       "      <td>Q2</td>\n",
       "      <td>R2</td>\n",
       "      <td>S2</td>\n",
       "      <td>T2</td>\n",
       "      <td>V2</td>\n",
       "      <td>W2</td>\n",
       "      <td>Y2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     ...                      \\\n",
       "AA  A-2  C-2  D-2  E-2  F-2  G-2  H-2  I-2  K-2  L-2 ...  N2  P2  Q2  R2  S2   \n",
       "      0    0    0    0    0    0    0    0    0    0 ...   0   0   0   0   0   \n",
       "\n",
       "                        \n",
       "AA  T2  V2  W2  Y2  -2  \n",
       "     0   0   0   0   0  \n",
       "\n",
       "[2 rows x 105 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex0 = skip_data.ix[2]\n",
    "pd.DataFrame([ex0.index, ex0.values], index=['AA', ''], columns=['']*105)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Feed Forward Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T17:24:49.194573",
     "start_time": "2016-05-07T17:24:48.184168"
    },
    "collapsed": true,
    "hide_input": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T17:38:35.157904",
     "start_time": "2016-05-07T17:38:32.155789"
    },
    "collapsed": false,
    "hide_input": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134815, 105) (134815, 6)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('5_formatted_fixed.csv').drop('Unnamed: 0', axis=1)\n",
    "labels = pd.read_csv('5_formatted_fixed_labels.csv').drop('Unnamed: 0', axis=1)\n",
    "print data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T17:38:39.697483",
     "start_time": "2016-05-07T17:38:39.255029"
    },
    "collapsed": false,
    "hide_input": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101111, 105) (101111, 6) (33704, 105) (33704, 6)\n"
     ]
    }
   ],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(np.asarray(data), np.asarray(labels))\n",
    "print xTrain.shape, yTrain.shape, xTest.shape, yTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T18:25:16.565690",
     "start_time": "2016-05-07T17:54:43.058130"
    },
    "collapsed": false,
    "hide_input": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.460573033597 0.462467362924\n",
      "1 0.478038986856 0.480239734156\n",
      "2 0.485960973583 0.487835271778\n",
      "3 0.498096151754 0.500029670069\n",
      "4 0.545885215258 0.548480892476\n",
      "5 0.556586325919 0.557826964159\n",
      "6 0.559256658524 0.559963209115\n",
      "7 0.565952270277 0.564947780679\n",
      "8 0.572499530219 0.571564206029\n",
      "9 0.577048985768 0.576430097318\n",
      "10 0.581143495762 0.580079515784\n",
      "11 0.583873169091 0.583372893425\n",
      "12 0.586187457349 0.58631023024\n",
      "13 0.590034714324 0.589336577261\n",
      "14 0.594000652748 0.593193686209\n",
      "15 0.598965493369 0.595359601234\n",
      "16 0.602970992276 0.599187040114\n",
      "17 0.605730335967 0.601798006171\n",
      "18 0.608885284489 0.604408972229\n",
      "19 0.610932539486 0.606604557323\n",
      "20 0.614413861993 0.60820674104\n",
      "21 0.617479799428 0.610194635652\n",
      "22 0.619358922372 0.611055067648\n",
      "23 0.621584199543 0.612597911227\n",
      "24 0.623601784178 0.614200094944\n",
      "25 0.62597541316 0.615179207216\n",
      "26 0.627666623809 0.615772608592\n",
      "27 0.629585307237 0.61737479231\n",
      "28 0.631503990664 0.618175884168\n",
      "29 0.6338083888 0.618976976027\n",
      "30 0.636290809111 0.619362686921\n",
      "31 0.638199602417 0.619985758367\n",
      "32 0.640246857414 0.621261571327\n",
      "33 0.642373233377 0.622151673392\n",
      "34 0.64449960934 0.621676952291\n",
      "35 0.647031480254 0.622537384287\n",
      "36 0.648683130421 0.622893425113\n",
      "37 0.650908407592 0.623931877522\n",
      "38 0.652411705947 0.623397816283\n",
      "39 0.654043575872 0.623664846902\n",
      "40 0.655685335918 0.624139568004\n",
      "41 0.65689193065 0.624347258486\n",
      "42 0.659087537459 0.62550439117\n",
      "43 0.660897429558 0.626186802753\n",
      "44 0.662321606947 0.626424163304\n",
      "45 0.664171059529 0.626691193924\n",
      "46 0.66602051211 0.62704723475\n",
      "47 0.667197436481 0.627699976264\n",
      "48 0.669205130995 0.627818656539\n",
      "49 0.670253483795 0.627670306195\n",
      "50 0.672023815411 0.628234037503\n",
      "51 0.673279860747 0.628619748398\n",
      "52 0.674931510914 0.628590078329\n",
      "53 0.676672172167 0.629569190601\n",
      "54 0.67775019533 0.629124139568\n",
      "55 0.678758987647 0.629242819843\n",
      "56 0.680291956365 0.629687870876\n",
      "57 0.681854595445 0.63034061239\n",
      "58 0.684000751649 0.631349394731\n",
      "59 0.684969983483 0.630934013767\n",
      "60 0.686532622563 0.63010325184\n",
      "61 0.688253503575 0.630370282459\n",
      "62 0.689588669878 0.63060764301\n",
      "63 0.690815044852 0.630429622597\n",
      "64 0.692506255501 0.630459292666\n",
      "65 0.693960103253 0.63111203418\n",
      "66 0.695591973178 0.632180156658\n",
      "67 0.696966699963 0.632180156658\n",
      "68 0.698252415662 0.631824115832\n",
      "69 0.699706263413 0.631794445763\n",
      "70 0.700813956938 0.632091146451\n",
      "71 0.703197476041 0.63339662948\n",
      "72 0.704423851015 0.634286731545\n",
      "73 0.705670006231 0.634286731545\n",
      "74 0.707410667484 0.634642772371\n",
      "75 0.708894185598 0.635028483266\n",
      "76 0.710011769244 0.634850462853\n",
      "77 0.711811771222 0.635236173748\n",
      "78 0.712929354867 0.634880132922\n",
      "79 0.713789795373 0.634464751958\n",
      "80 0.71531287397 0.634731782578\n",
      "81 0.716242545321 0.635028483266\n",
      "82 0.717459030175 0.635354854023\n",
      "83 0.719041449496 0.635977925469\n",
      "84 0.72052496761 0.636304296226\n",
      "85 0.722245848622 0.637075718016\n",
      "86 0.723670026011 0.637491098979\n",
      "87 0.725153544125 0.638470211251\n",
      "88 0.726627172118 0.638410871113\n",
      "89 0.728259042043 0.638529551389\n",
      "90 0.729366735568 0.638766911939\n",
      "91 0.730978825251 0.639746024211\n",
      "92 0.732590914935 0.640606456207\n",
      "93 0.733639267735 0.641318537859\n",
      "94 0.735023884642 0.642208639924\n",
      "95 0.735735973336 0.642089959649\n",
      "96 0.737130480363 0.643247092333\n",
      "97 0.738475536786 0.643276762402\n",
      "98 0.739870043813 0.644196534536\n",
      "99 0.741116199029 0.644315214811\n",
      "100 0.742164551829 0.644048184192\n",
      "101 0.742995321973 0.644018514123\n",
      "102 0.744459059845 0.644908616188\n",
      "103 0.745131588057 0.645175646808\n",
      "104 0.746397523514 0.645353667221\n",
      "105 0.747346975107 0.645205316876\n",
      "106 0.748345877303 0.644433895087\n",
      "107 0.750046978074 0.644285544742\n",
      "108 0.75104588027 0.643988844054\n",
      "109 0.752311815727 0.643810823641\n",
      "110 0.753340388286 0.644137194398\n",
      "111 0.754556873139 0.643899833848\n",
      "112 0.75574368763 0.644285544742\n",
      "113 0.757227205744 0.644789935913\n",
      "114 0.758552481926 0.644878946119\n",
      "115 0.760026109919 0.645353667221\n",
      "116 0.761064572598 0.64511630667\n",
      "117 0.762142595761 0.645650367909\n",
      "118 0.763715124962 0.646332779492\n",
      "119 0.765109631989 0.646718490387\n",
      "120 0.766355787204 0.646303109423\n",
      "121 0.767681063386 0.646807500593\n",
      "122 0.768877767998 0.647193211488\n",
      "123 0.769619527054 0.647519582245\n",
      "124 0.771459089515 0.648231663897\n",
      "125 0.772616233644 0.648469024448\n",
      "126 0.773931619705 0.6491811061\n",
      "127 0.774960192264 0.649626157133\n",
      "128 0.776008545064 0.650100878234\n",
      "129 0.776918436174 0.650812959886\n",
      "130 0.778342613563 0.650545929267\n",
      "131 0.779638219383 0.650872300024\n",
      "132 0.780736022787 0.651436031332\n",
      "133 0.782130529814 0.651673391882\n",
      "134 0.783673388652 0.652326133397\n",
      "135 0.785147016645 0.653097555186\n",
      "136 0.786086578117 0.653661286494\n",
      "137 0.786996469227 0.653720626632\n",
      "138 0.788242624442 0.653542606219\n",
      "139 0.78937998833 0.653690956563\n",
      "140 0.790725044753 0.65377996677\n",
      "141 0.791634935863 0.654403038215\n",
      "142 0.79291076144 0.654670068835\n",
      "143 0.793840432792 0.654848089248\n",
      "144 0.795195379336 0.655589840968\n",
      "145 0.796738238174 0.656598623309\n",
      "146 0.797816261337 0.656598623309\n",
      "147 0.798914064741 0.656895323997\n",
      "148 0.79968549416 0.656835983859\n",
      "149 0.800773407443 0.657043674341\n",
      "150 0.801604177587 0.657043674341\n",
      "151 0.802454727972 0.657251364823\n",
      "152 0.803384399324 0.657281034892\n",
      "153 0.804373411399 0.6578447662\n",
      "154 0.805530555528 0.65834915737\n",
      "155 0.806836051468 0.658230477095\n",
      "156 0.807864624027 0.658260147164\n",
      "157 0.808408580669 0.658319487301\n",
      "158 0.80973385685 0.658111796819\n",
      "159 0.810653638081 0.658141466888\n",
      "160 0.8114250675 0.658467837645\n",
      "161 0.81207781547 0.657963446475\n",
      "162 0.813205289237 0.65834915737\n",
      "163 0.814629466626 0.65912057916\n",
      "164 0.815658039185 0.65885354854\n",
      "165 0.816627271019 0.658883218609\n",
      "166 0.817754744785 0.659506290055\n",
      "167 0.818644855654 0.659031568953\n",
      "168 0.81951518628 0.65912057916\n",
      "169 0.820247055217 0.658764538334\n",
      "170 0.821186616689 0.658556847852\n",
      "171 0.822304200334 0.658942558747\n",
      "172 0.823263542048 0.659535960123\n",
      "173 0.823975630742 0.659268929504\n",
      "174 0.825004203301 0.659150249229\n",
      "175 0.825923984532 0.65935793971\n",
      "176 0.826833875642 0.65962497033\n",
      "177 0.827644865544 0.659535960123\n",
      "178 0.828802009673 0.6601293615\n",
      "179 0.829533878609 0.66039639212\n",
      "180 0.830552561047 0.66063375267\n",
      "181 0.831571243485 0.661256824116\n",
      "182 0.832392123508 0.661553524804\n",
      "183 0.833183333168 0.661583194873\n",
      "184 0.833638278723 0.661494184667\n",
      "185 0.834429488384 0.661494184667\n",
      "186 0.835092126475 0.661939235699\n",
      "187 0.836170149638 0.66167220508\n",
      "188 0.836882238332 0.661761215286\n",
      "189 0.837722898597 0.662265606456\n",
      "190 0.838474547774 0.662473296938\n",
      "191 0.839008614295 0.662324946594\n",
      "192 0.839819604197 0.662710657489\n",
      "193 0.840600923737 0.663304058865\n",
      "194 0.841392133398 0.66318537859\n",
      "195 0.842213013421 0.663096368384\n",
      "196 0.842845981149 0.662591977213\n",
      "197 0.843469058757 0.663244718728\n",
      "198 0.844131696848 0.663096368384\n",
      "199 0.844853675663 0.663066698315\n",
      "200 0.845664665566 0.662859007833\n",
      "201 0.846347083898 0.662799667695\n",
      "202 0.847227304645 0.662473296938\n",
      "203 0.84781082177 0.662740327558\n",
      "204 0.848621811672 0.663155708521\n",
      "205 0.849521812661 0.663037028246\n",
      "206 0.316295951974 0.31746973653\n",
      "207 0.316295951974 0.31746973653\n",
      "208 0.316295951974 0.31746973653\n",
      "209 0.316295951974 0.31746973653\n",
      "210 0.316295951974 0.31746973653\n",
      "211 0.316295951974 0.31746973653\n",
      "212 0.316295951974 0.31746973653\n",
      "213 0.316295951974 0.31746973653\n",
      "214 0.316295951974 0.31746973653\n",
      "215 0.316295951974 0.31746973653\n",
      "216 0.316295951974 0.31746973653\n",
      "217 0.316295951974 0.31746973653\n",
      "218 0.316295951974 0.31746973653\n",
      "219 0.316295951974 0.31746973653\n",
      "220 0.316295951974 0.31746973653\n",
      "221 0.316295951974 0.31746973653\n",
      "222 0.316295951974 0.31746973653\n",
      "223 0.316295951974 0.31746973653\n",
      "224 0.316295951974 0.31746973653\n",
      "225 0.316295951974 0.31746973653\n",
      "226 0.316295951974 0.31746973653\n",
      "227 0.316295951974 0.31746973653\n",
      "228 0.316295951974 0.31746973653\n",
      "229 0.316295951974 0.31746973653\n",
      "230 0.316295951974 0.31746973653\n",
      "231 0.316295951974 0.31746973653\n",
      "232 0.316295951974 0.31746973653\n",
      "233 0.316295951974 0.31746973653\n",
      "234 0.316295951974 0.31746973653\n",
      "235 0.316295951974 0.31746973653\n",
      "236 0.316295951974 0.31746973653\n",
      "237 0.316295951974 0.31746973653\n",
      "238 0.316295951974 0.31746973653\n",
      "239 0.316295951974 0.31746973653\n",
      "240 0.316295951974 0.31746973653\n",
      "241 0.316295951974 0.31746973653\n",
      "242 0.316295951974 0.31746973653\n",
      "243 0.316295951974 0.31746973653\n",
      "244 0.316295951974 0.31746973653\n",
      "245 0.316295951974 0.31746973653\n",
      "246 0.316295951974 0.31746973653\n",
      "247 0.316295951974 0.31746973653\n",
      "248 0.316295951974 0.31746973653\n",
      "249 0.316295951974 0.31746973653\n",
      "250 0.316295951974 0.31746973653\n",
      "251 0.316295951974 0.31746973653\n",
      "252 0.316295951974 0.31746973653\n",
      "253 0.316295951974 0.31746973653\n",
      "254 0.316295951974 0.31746973653\n",
      "255 0.316295951974 0.31746973653\n",
      "256 0.316295951974 0.31746973653\n",
      "257 0.316295951974 0.31746973653\n",
      "258 0.316295951974 0.31746973653\n",
      "259 0.316295951974 0.31746973653\n",
      "260 0.316295951974 0.31746973653\n",
      "261 0.316295951974 0.31746973653\n",
      "262 0.316295951974 0.31746973653\n",
      "263 0.316295951974 0.31746973653\n",
      "264 0.316295951974 0.31746973653\n",
      "265 0.316295951974 0.31746973653\n",
      "266 0.316295951974 0.31746973653\n",
      "267 0.316295951974 0.31746973653\n",
      "268 0.316295951974 0.31746973653\n",
      "269 0.316295951974 0.31746973653\n",
      "270 0.316295951974 0.31746973653\n",
      "271 0.316295951974 0.31746973653\n",
      "272 0.316295951974 0.31746973653\n",
      "273 0.316295951974 0.31746973653\n",
      "274 0.316295951974 0.31746973653\n",
      "275 0.316295951974 0.31746973653\n",
      "276 0.316295951974 0.31746973653\n",
      "277 0.316295951974 0.31746973653\n",
      "278 0.316295951974 0.31746973653\n",
      "279 0.316295951974 0.31746973653\n",
      "280 0.316295951974 0.31746973653\n",
      "281 0.316295951974 0.31746973653\n",
      "282 0.316295951974 0.31746973653\n",
      "283 0.316295951974 0.31746973653\n",
      "284 0.316295951974 0.31746973653\n",
      "285 0.316295951974 0.31746973653\n",
      "286 0.316295951974 0.31746973653\n",
      "287 0.316295951974 0.31746973653\n",
      "288 0.316295951974 0.31746973653\n",
      "289 0.316295951974 0.31746973653\n",
      "290 0.316295951974 0.31746973653\n",
      "291 0.316295951974 0.31746973653\n",
      "292 0.316295951974 0.31746973653\n",
      "293 0.316295951974 0.31746973653\n",
      "294 0.316295951974 0.31746973653\n",
      "295 0.316295951974 0.31746973653\n",
      "296 0.316295951974 0.31746973653\n",
      "297 0.316295951974 0.31746973653\n",
      "298 0.316295951974 0.31746973653\n",
      "299 0.316295951974 0.31746973653\n",
      "300 0.316295951974 0.31746973653\n",
      "301 0.316295951974 0.31746973653\n",
      "302 0.316295951974 0.31746973653\n",
      "303 0.316295951974 0.31746973653\n",
      "304 0.316295951974 0.31746973653\n",
      "305 0.316295951974 0.31746973653\n",
      "306 0.316295951974 0.31746973653\n",
      "307 0.316295951974 0.31746973653\n",
      "308 0.316295951974 0.31746973653\n",
      "309 0.316295951974 0.31746973653\n",
      "310 0.316295951974 0.31746973653\n",
      "311 0.316295951974 0.31746973653\n",
      "312 0.316295951974 0.31746973653\n",
      "313 0.316295951974 0.31746973653\n",
      "314 0.316295951974 0.31746973653\n",
      "315 0.316295951974 0.31746973653\n",
      "316 0.316295951974 0.31746973653\n",
      "317 0.316295951974 0.31746973653\n",
      "318 0.316295951974 0.31746973653\n",
      "319 0.316295951974 0.31746973653\n",
      "320 0.316295951974 0.31746973653\n",
      "321 0.316295951974 0.31746973653\n",
      "322 0.316295951974 0.31746973653\n",
      "323 0.316295951974 0.31746973653\n",
      "324 0.316295951974 0.31746973653\n",
      "325 0.316295951974 0.31746973653\n",
      "326 0.316295951974 0.31746973653\n",
      "327 0.316295951974 0.31746973653\n",
      "328 0.316295951974 0.31746973653\n",
      "329 0.316295951974 0.31746973653\n",
      "330 0.316295951974 0.31746973653\n",
      "331 0.316295951974 0.31746973653\n",
      "332 0.316295951974 0.31746973653\n",
      "333 0.316295951974 0.31746973653\n",
      "334 0.316295951974 0.31746973653\n",
      "335 0.316295951974 0.31746973653\n",
      "336 0.316295951974 0.31746973653\n",
      "337 0.316295951974 0.31746973653\n",
      "338 0.316295951974 0.31746973653\n",
      "339 0.316295951974 0.31746973653\n",
      "340 0.316295951974 0.31746973653\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-bb10d462492f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mtest_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    (h, w) = shape\n",
    "    normalizer = 2.0 * sqrt(6) / sqrt(h + w) * 0.1  #factors: correct for uni[0,1], glo, glo, softmax deriv\n",
    "    return theano.shared(floatX((np.random.random_sample(shape) - 0.5) * normalizer))  #code for using Glorot init\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "def model(X, w_h, w_o):\n",
    "    h = T.nnet.sigmoid(T.dot(X, w_h))\n",
    "    pyx = T.nnet.softmax(T.dot(h, w_o))\n",
    "    return pyx\n",
    "\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "w_h = init_weights((105, 600))\n",
    "w_o = init_weights((600, 6))\n",
    "\n",
    "py_x = model(X, w_h, w_o)\n",
    "y_pred = T.argmax(py_x, axis=1)\n",
    "\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(py_x, Y))\n",
    "params = [w_h, w_o]\n",
    "\n",
    "update = RMSprop(cost, params, lr=0.005)\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "costs = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in range(501):\n",
    "    for start, end in zip(range(0, len(xTrain), 128), range(128, len(xTrain), 128)):\n",
    "        cost = train(xTrain[start:end], yTrain[start:end])\n",
    "    \n",
    "    costs.append(cost)\n",
    "    \n",
    "    train_acc = np.mean(np.argmax(yTrain, axis=1) == predict(xTrain))\n",
    "    \n",
    "    test_acc = np.mean(np.argmax(yTest, axis=1) == predict(xTest))\n",
    "    \n",
    "    test_scores.append(test_acc)\n",
    "    train_scores.append(train_acc)\n",
    "    \n",
    "    print i, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T18:25:20.189075",
     "start_time": "2016-05-07T18:25:19.824812"
    },
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAESCAYAAADuVeJ5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYRoFgkMIYQQzSKBIYQQoln+PzdN+UY2cyDdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1180e4710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_scores, label='train')\n",
    "plt.plot(test_scores, label='test')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-07T18:25:20.484909",
     "start_time": "2016-05-07T18:25:20.191455"
    },
    "collapsed": false,
    "hide_input": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEDCAYAAADZUdTgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f968f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(costs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It took me a while to realize, but what seems to be happening is that the weights are going to zero. In this case, all of our predictions are going to be for class zero. Class zero corresponds to fold state H. Due to the class imbalance, the p(H) is this ~32% accuracy, which explains the constant accuracy score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thus, the Gradients must be vanishing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding convolution complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returning to our example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T11:22:09.454635",
     "start_time": "2016-05-09T11:22:09.449743"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V' 'L' 'S' 'P' 'A']\n"
     ]
    }
   ],
   "source": [
    "print seq[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T11:16:09.798603",
     "start_time": "2016-05-09T11:16:09.779436"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V-2', 'L-1', 'S0', 'P1', 'A2']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['V-2', 'L-1', 'S0', 'P1', 'A2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T11:16:36.931343",
     "start_time": "2016-05-09T11:16:36.733942"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>A-2</td>\n",
       "      <td>C-2</td>\n",
       "      <td>D-2</td>\n",
       "      <td>E-2</td>\n",
       "      <td>F-2</td>\n",
       "      <td>G-2</td>\n",
       "      <td>H-2</td>\n",
       "      <td>I-2</td>\n",
       "      <td>K-2</td>\n",
       "      <td>L-2</td>\n",
       "      <td>...</td>\n",
       "      <td>N2</td>\n",
       "      <td>P2</td>\n",
       "      <td>Q2</td>\n",
       "      <td>R2</td>\n",
       "      <td>S2</td>\n",
       "      <td>T2</td>\n",
       "      <td>V2</td>\n",
       "      <td>W2</td>\n",
       "      <td>Y2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     ...                      \\\n",
       "AA  A-2  C-2  D-2  E-2  F-2  G-2  H-2  I-2  K-2  L-2 ...  N2  P2  Q2  R2  S2   \n",
       "      0    0    0    0    0    0    0    0    0    0 ...   0   0   0   0   0   \n",
       "\n",
       "                        \n",
       "AA  T2  V2  W2  Y2  -2  \n",
       "     0   0   0   0   0  \n",
       "\n",
       "[2 rows x 105 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex0 = skip_data.ix[2]\n",
    "pd.DataFrame([ex0.index, ex0.values], index=['AA', ''], columns=['']*105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T14:21:59.832433",
     "start_time": "2016-05-09T14:21:44.153873"
    },
    "collapsed": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# read our data in \n",
    "\n",
    "aminos = ['-','A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "positions = sorted(map(str, range(-(n_window-1)//2, (n_window+1)//2, 1)))\n",
    "\n",
    "n_window = 13\n",
    "n_aminos = 21\n",
    "\n",
    "loaded_data = get_data_tensor(n = n_window)\n",
    "    \n",
    "labels = pd.read_csv('one_hot_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We reformat each protein context into an \"image\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T11:18:26.034948",
     "start_time": "2016-05-09T11:18:25.993946"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    -  A  C  D  E  F  G  H  I  K  L  M  N  P  Q  R  S  T  V  W  Y\n",
    "-1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
    "-2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
    "0   0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
    "1   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0\n",
    "2   0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T14:24:21.352761",
     "start_time": "2016-05-09T14:24:20.897769"
    },
    "collapsed": false,
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADuCAYAAAAZZe3jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZGcUeEWEckZFW4RkZxR4RYRyZn/D9AUtmEdFSDWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120fd7410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(loaded_data[:1].reshape((13, 21)));\n",
    "plt.xticks(xrange(len(aminos)), aminos)\n",
    "plt.yticks(xrange(len(positions)), positions);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Build the Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T14:38:07.871793",
     "start_time": "2016-05-09T14:38:07.860083"
    },
    "collapsed": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# theano imports\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "# from theano.tensor.signal.downsample import max_pool_2d\n",
    "from theano.tensor.signal.pool import pool_2d as max_pool_2d\n",
    "from theano.tensor.nnet import batch_normalization\n",
    "\n",
    "# other imports\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we will apply a series of convolutional filters (256) to the amino image, and receive a scalar representing the Amino Acid and its context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"Conv_Filter.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T21:34:27.292468",
     "start_time": "2016-05-09T21:34:27.231068"
    },
    "collapsed": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# helper function for loading in data of a specific encoding window\n",
    "def get_data_tensor(n = 5):\n",
    "    filename = 'conv_data/' + str(n) + '_tensor.p'\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    \n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T21:34:42.693529",
     "start_time": "2016-05-09T21:34:27.486389"
    },
    "collapsed": true,
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# read our data in \n",
    "\n",
    "n_window = 13\n",
    "n_aminos = 21\n",
    "\n",
    "loaded_data = get_data_tensor(n = n_window)\n",
    "    \n",
    "labels = pd.read_csv('one_hot_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T21:34:43.179872",
     "start_time": "2016-05-09T21:34:42.699456"
    },
    "collapsed": false,
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101110, 1, 13, 21) (33704, 1, 13, 21) (101110, 6) (33704, 6)\n"
     ]
    }
   ],
   "source": [
    "one_hot = labels.values\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(loaded_data, one_hot)\n",
    "xTrain = xTrain.reshape(-1, 1, n_window, n_aminos)\n",
    "xTest = xTest.reshape(-1, 1, n_window, n_aminos)\n",
    "\n",
    "print xTrain.shape, xTest.shape, yTrain.shape, yTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T21:34:43.513137",
     "start_time": "2016-05-09T21:34:43.190359"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def glorot_init_weights(shape):\n",
    "    (h, w) = shape\n",
    "    # 0.25 for sigmoid, 0.1 for softmax, 1.0 for tanh/relu\n",
    "    normalizer = 2.0 * (6**0.5) / ((h + w)**0.5) * 1.0  #factors: 0.1 correct for uni[0,1], glo, glo, softmax deriv\n",
    "    return theano.shared(floatX((np.random.random_sample(shape) - 0.5) * normalizer))\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "def activate(X):\n",
    "    return T.nnet.relu(X)\n",
    "\n",
    "def rectify(X):\n",
    "#     return T.maximum(X, 0.)\n",
    "    return T.maximum(X, 0.01*X)  #leaky rectifier\n",
    "\n",
    "def ELU(X, alpha=0.1):\n",
    "    return T.switch(X > 0, X, alpha * (T.exp(X) - 1))\n",
    "    \n",
    "def softmax(X):\n",
    "    e_x = T.exp(X - X.max(axis=1).dimshuffle(0, 1, 'x', 'x'))\n",
    "    return e_x / e_x.sum(axis=1).dimshuffle(0, 1, 'x', 'x')\n",
    "\n",
    "def dropout(X, p=0.0):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    \n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    \n",
    "    return updates\n",
    "\n",
    "def model(X, wi, wh, bh, wo, bo, p_drop_conv, p_drop_hidden):\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    \n",
    "    layer_1 = conv2d(X, wi, border_mode='valid')\n",
    "    layer_1 = layer_1.reshape((-1, 256))\n",
    "    layer_1 = dropout(layer_1, p_drop_conv)\n",
    "\n",
    "    # --------------------------------------------\n",
    "    \n",
    "    layer_2 = T.dot(layer_1, wh) + bh    \n",
    "    layer_2 = ELU(layer_2)\n",
    "    layer_2 = dropout(layer_2, p_drop_hidden)\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    \n",
    "    layer_3 = T.dot(layer_2, wo) + bo\n",
    "    layer_3 = dropout(layer_3, p_drop_hidden)\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    \n",
    "#     pyx = softmax(layer_3)\n",
    "    pyx = T.nnet.softmax(layer_3)\n",
    "    return layer_1, layer_2, layer_3, pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T21:35:21.838270",
     "start_time": "2016-05-09T21:35:20.188861"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = T.ftensor4()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "# define number of desired features out of convolution\n",
    "n_conv = 256\n",
    "\n",
    "# define hidden layer depth\n",
    "h_depth = 50\n",
    "\n",
    "# define output layer size\n",
    "o_depth = 6\n",
    "\n",
    "# ----------------------------- FOR WITHOUT BATCH NORMALIZATION------------------------------\n",
    "\n",
    "# input parameters\n",
    "wi = init_weights((n_conv, 1, n_window, n_aminos))\n",
    "\n",
    "# hidden parameters\n",
    "wh = glorot_init_weights((n_conv, h_depth))\n",
    "bh = theano.shared(floatX(np.zeros(h_depth)))\n",
    "\n",
    "# output parameters\n",
    "wo = glorot_init_weights((h_depth, o_depth))\n",
    "bo = theano.shared(floatX(np.zeros(o_depth)))\n",
    "\n",
    "# modeling and parameters for Gradient Descent\n",
    "params = [wi, wh, bh, wo, bo]\n",
    "noise_l1, noise_l2, noise_l3, noise_py_x = model(X, wi, wh, bh, wo, bo, 0.2, 0.5)\n",
    "l1, l2, l3, py_x = model(X, wi, wh, bh, wo, bo, 0., 0.)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "updates = RMSprop(cost, params, lr=1e-4) \n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-05-10T04:35:25.023Z"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 ------- train: 0.616 ------- test: 0.612\n",
      "1st filter: [ 0.00399164  0.00790589  0.00421786  0.00330725 -0.00131144]\n",
      "------------------------------------------------------------\n",
      "iteration: 1 ------- train: 0.626 ------- test: 0.622\n",
      "1st filter: [ 0.00061803  0.00970135  0.00475286  0.00108363 -0.0030484 ]\n",
      "------------------------------------------------------------\n",
      "iteration: 2 ------- train: 0.63 ------- test: 0.624\n",
      "1st filter: [ 0.00138729  0.01095211  0.00632949  0.00159674 -0.00227471]\n",
      "------------------------------------------------------------\n",
      "iteration: 3 ------- train: 0.63 ------- test: 0.625\n",
      "1st filter: [-0.00113194  0.01244355  0.00889163  0.00013126 -0.00151669]\n",
      "------------------------------------------------------------\n",
      "iteration: 4 ------- train: 0.632 ------- test: 0.626\n",
      "1st filter: [-0.00573713  0.01322613  0.00944777  0.00273066 -0.00183793]\n",
      "------------------------------------------------------------\n",
      "iteration: 5 ------- train: 0.631 ------- test: 0.626\n",
      "1st filter: [-0.00835437  0.01304678  0.00632354  0.00249911 -0.00397471]\n",
      "------------------------------------------------------------\n",
      "iteration: 6 ------- train: 0.634 ------- test: 0.627\n",
      "1st filter: [-0.00930321  0.0134903   0.00680824  0.00067888 -0.00028612]\n",
      "------------------------------------------------------------\n",
      "iteration: 7 ------- train: 0.635 ------- test: 0.629\n",
      "1st filter: [-0.00732885  0.01317963  0.00724721  0.00243085 -0.00020169]\n",
      "------------------------------------------------------------\n",
      "iteration: 8 ------- train: 0.636 ------- test: 0.63\n",
      "1st filter: [ -6.20682584e-03   1.67707298e-02   9.50545724e-03  -4.55069356e-04\n",
      "  -1.77018701e-05]\n",
      "------------------------------------------------------------\n",
      "iteration: 9 ------- train: 0.637 ------- test: 0.63\n",
      "1st filter: [-0.00824594  0.01624487  0.00408329  0.00065469  0.00289394]\n",
      "------------------------------------------------------------\n",
      "iteration: 10 ------- train: 0.638 ------- test: 0.631\n",
      "1st filter: [-0.0096489   0.01765324  0.00535916  0.00037451  0.00237676]\n",
      "------------------------------------------------------------\n",
      "iteration: 11 ------- train: 0.638 ------- test: 0.632\n",
      "1st filter: [-0.01094471  0.017937    0.00636138  0.00218356  0.00581773]\n",
      "------------------------------------------------------------\n",
      "iteration: 12 ------- train: 0.639 ------- test: 0.632\n",
      "1st filter: [-0.00765804  0.02050584  0.00592595  0.00150163  0.00425239]\n",
      "------------------------------------------------------------\n",
      "iteration: 13 ------- train: 0.64 ------- test: 0.633\n",
      "1st filter: [-0.00594607  0.01957198  0.00440041  0.00465909  0.00248728]\n",
      "------------------------------------------------------------\n",
      "iteration: 14 ------- train: 0.641 ------- test: 0.635\n",
      "1st filter: [-0.00787129  0.01866877  0.00742298  0.00864384  0.00334616]\n",
      "------------------------------------------------------------\n",
      "iteration: 15 ------- train: 0.643 ------- test: 0.635\n",
      "1st filter: [-0.00786222  0.02076895  0.00661149  0.00804241  0.0028325 ]\n",
      "------------------------------------------------------------\n",
      "iteration: 16 ------- train: 0.643 ------- test: 0.636\n",
      "1st filter: [-0.00646189  0.02163033  0.00892832  0.00830388  0.00440606]\n",
      "------------------------------------------------------------\n",
      "iteration: 17 ------- train: 0.644 ------- test: 0.636\n",
      "1st filter: [-0.00723302  0.02295104  0.00704637  0.00790386  0.00707599]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# number of training iterations to perform\n",
    "n_train = 31\n",
    "\n",
    "# define mini-batch size\n",
    "mbs = 128\n",
    "\n",
    "# store our results\n",
    "costs = []\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "\n",
    "# performing our training\n",
    "for i in xrange(n_train):\n",
    "    \n",
    "    for start, end in zip(xrange(0, len(xTrain), mbs), \n",
    "                          xrange(mbs, len(xTrain), mbs)):\n",
    "    \n",
    "        cost = train(xTrain[start:end], yTrain[start:end])\n",
    "    \n",
    "    costs.append(cost)\n",
    "    \n",
    "    train_score = np.mean(np.argmax(yTrain, axis=1) == predict(xTrain)) \n",
    "    test_score = np.mean(np.argmax(yTest, axis=1) == predict(xTest))\n",
    "    \n",
    "    test_scores.append(test_score)\n",
    "    train_scores.append(train_score)\n",
    "    \n",
    "    print 'iteration:', i, '-------', 'train:', round(train_score, 3), '-------', 'test:', round(test_score, 3)\n",
    "    print '1st filter:', wi.eval()[0][0][0][:5] # take a quick look at conv filter\n",
    "    print '-'*60\n",
    "    \n",
    "# got up to about 67% w/ 5 vectors!\n",
    "# up to like 69% with a 9 vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How we are doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T14:53:21.609270",
     "start_time": "2016-05-09T14:53:21.192953"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-14d6d0e50dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot our accuracies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Steps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3152\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3153\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3155\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3156\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1810\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1811\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1812\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'color'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must have same first dimension\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y can be no greater than 2-D\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEDCAYAAAA2k7/eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwZekIgy+JBVh8CWpCIMvSUX8P681eoBceRoxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120da2ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot our accuracies\n",
    "plt.plot(xrange(n_train), train_scores, label='train')\n",
    "plt.plot(xrange(n_train), test_scores, label='test')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-05-09T14:53:26.902052",
     "start_time": "2016-05-09T14:53:26.128429"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-9f0f26e95de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot our cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Steps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3152\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3153\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3155\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3156\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1810\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1811\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1812\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'color'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/LucasRamadan/anaconda/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must have same first dimension\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y can be no greater than 2-D\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEDCAYAAAA2k7/eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwZekIgy+JBVh8CWpCIMvSUX8P681eoBceRoxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120c54350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot our cost\n",
    "plt.plot(xrange(n_train), costs)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Cost');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look at the Convolutional Filters (Amino Maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AMINO MAPS (n_window, 21)\n",
    "aminos = ['-','A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "# positions = ['-1', '-2', '0', '1', '2']\n",
    "\n",
    "positions = sorted(map(str, range(-(n_window-1)//2, (n_window+1)//2, 1)))\n",
    "\n",
    "for conv in wi.eval()[:5]:\n",
    "    c = conv.reshape(n_window, n_aminos)\n",
    "    plt.imshow(c, cmap='Greys')\n",
    "    plt.xticks(range(len(aminos)), aminos)\n",
    "    plt.yticks(range(len(positions)), positions)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# hoping to get batch normalization implemented below\n",
    "# data, input weights, gamma input, beta input, hidden weights, hidden bias, gamma hidden, beta hidden, \n",
    "# output weights, output bias, gamma output, beta output, p_drop, p_hidden_drop\n",
    "def model_bn(X, wi, gi, bbi, wh, bh, gh, bbh, wo, bo, go, bbo, p_drop_conv, p_drop_hidden):\n",
    "\n",
    "    # --------------------------------------------\n",
    "    \n",
    "    layer_1 = conv2d(X, wi, border_mode='valid')\n",
    "    layer_1 = layer_1.reshape((-1, 256))\n",
    "    layer_1 = batch_normalization(layer_1, gamma=gi, beta=bbi, \n",
    "                                 mean=layer_1.mean((0, ), keepdims=True), \n",
    "                                  std = T.ones_like(layer_1.var((0,), keepdims=True)), \n",
    "                                  mode='high_mem')\n",
    "\n",
    "    layer_1 = dropout(layer_1, p_drop_conv)\n",
    "\n",
    "    # --------------------------------------------\n",
    "    \n",
    "    layer_2 = T.dot(layer_1, wh) + bh\n",
    "    layer_2 = batch_normalization(layer_2, gamma=gh, beta=bbh, \n",
    "                                 mean=X.mean((0, ), keepdims=True), \n",
    "                                  std = T.ones_like(layer_2.var((0,), keepdims=True)), \n",
    "                                  mode='high_mem')\n",
    "    \n",
    "    layer_2 = activate(layer_2)\n",
    "    layer_2 = dropout(layer_2, p_drop_hidden)\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    \n",
    "    layer_3 = T.dot(layer_2, wo) + bo\n",
    "    layer_3 = batch_normalization(layer_3, gamma=go, beta=bbo, \n",
    "                                 mean=X.mean((0, ), keepdims=True), \n",
    "                                  std = T.ones_like(layer_3.var((0,), keepdims=True)), \n",
    "                                  mode='high_mem')\n",
    "    \n",
    "    layer_3 = dropout(layer_3, p_drop_hidden)\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    \n",
    "    # thinks it's getting a 4D Tensor ???\n",
    "#     pyx = softmax(layer_3)\n",
    "    pyx = T.nnet.softmax(layer_3)\n",
    "    return layer_1, layer_2, layer_3, pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = T.ftensor4()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "# define number of desired features out of convolution\n",
    "n_conv = 256\n",
    "\n",
    "# define hidden layer depth\n",
    "h_depth = 600\n",
    "\n",
    "# define output layer size\n",
    "o_depth = 6\n",
    "\n",
    "# --------------------------- FOR BATCH NORMALIZATION -----------------------\n",
    "\n",
    "# initialize weight matrices: wi, gi, bbi, wh, bh, gh, bbh, wo, bo, go, bbo\n",
    "\n",
    "# input parameters\n",
    "wi = init_weights((n_conv, 1, n_window, n_aminos))\n",
    "gi = theano.shared(floatX(np.ones(n_conv)))\n",
    "bbi = theano.shared(floatX(np.zeros(n_conv)))\n",
    "\n",
    "# hidden parameters\n",
    "wh = glorot_init_weights((n_conv, h_depth))\n",
    "bh = theano.shared(floatX(np.zeros(h_depth)))\n",
    "gh = theano.shared(floatX(np.ones(h_depth)))\n",
    "bbh = theano.shared(floatX(np.zeros(h_depth)))\n",
    "\n",
    "# output parameters\n",
    "wo = glorot_init_weights((h_depth, o_depth))\n",
    "bo = theano.shared(floatX(np.zeros(o_depth)))\n",
    "go = theano.shared(floatX(np.ones(o_depth)))\n",
    "bbo = theano.shared(floatX(np.zeros(o_depth)))\n",
    "\n",
    "# modeling and parameters for Gradient Descent\n",
    "noise_l1, noise_l2, noise_l3, noise_py_x = model(X, wi, gi, bbi, wh, bh, gh, bbh, wo, bo, go, bbo, 0.2, 0.5)\n",
    "l1, l2, l3, py_x = model(X, wi, gi, bbi, wh, bh, gh, bbh, wo, bo, go, bbo, 0., 0.)\n",
    "params = [wi, gi, bbi, wh, bh, gh, bbh, wo, bo, go, bbo]\n",
    "\n",
    "# output and training \n",
    "\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y))\n",
    "updates = RMSprop(cost, params, lr=1e-4) #lr=1e-7 <--- way too small of a LR\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of training iterations to perform\n",
    "n_train = 31\n",
    "\n",
    "# define mini-batch size\n",
    "mbs = 128\n",
    "\n",
    "# store our results\n",
    "costs = []\n",
    "test_scores = []\n",
    "train_scores = []\n",
    "\n",
    "# performing our training\n",
    "for i in xrange(n_train):\n",
    "    \n",
    "    for start, end in zip(xrange(0, len(xTrain), mbs), \n",
    "                          xrange(mbs, len(xTrain), mbs)):\n",
    "    \n",
    "        cost = train(xTrain[start:end], yTrain[start:end])\n",
    "    \n",
    "    costs.append(cost)\n",
    "    \n",
    "    train_score = np.mean(np.argmax(yTrain, axis=1) == predict(xTrain)) \n",
    "    test_score = np.mean(np.argmax(yTest, axis=1) == predict(xTest))\n",
    "    \n",
    "    test_scores.append(test_score)\n",
    "    train_scores.append(train_score)\n",
    "    \n",
    "    print 'iteration:', i, '-------', 'train:', round(train_score, 3), '-------', 'test:', round(test_score, 3)\n",
    "    print wi.eval()[0][0][0][:5] # take a quick look at conv filter\n",
    "    print '-'*60\n",
    "    \n",
    "# got up to about 67% w/ 5 vectors!\n",
    "# up to like 69% with a 9 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot our accuracies\n",
    "plt.plot(xrange(n_train), train_scores, label='train')\n",
    "plt.plot(xrange(n_train), test_scores, label='test')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot our cost\n",
    "plt.plot(xrange(n_train), costs)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Cost');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Added GRU between Convolutional Layer and Feed Foward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input --Conv--> ConvOut --GRU--> GRUOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srng = RandomStreams()\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def glorot_init_weights(shape):\n",
    "    (h, w) = shape\n",
    "    normalizer = 2.0 * (6**0.5) / ((h + w)**0.5) * 0.1  #factors: correct for uni[0,1], glo, glo, softmax deriv\n",
    "    return theano.shared(floatX((np.random.random_sample(shape) - 0.5) * normalizer))\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "def activ(x, f=None):\n",
    "    if f == 'tan':\n",
    "        return T.tanh(x)\n",
    "    else:\n",
    "        return T.nnet.sigmoid(x)\n",
    "\n",
    "def ELU(X, alpha=0.1):\n",
    "    return T.switch(X > 0, X, alpha * (T.exp(X) - 1))\n",
    "    \n",
    "def dropout(X, p=0.0):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "    \n",
    "def RMSprop(cost, params, lr=1e-3, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    \n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    \n",
    "    return updates\n",
    "\n",
    "def conv_model(X, wc, wh=None, p_drop_conv=0.0, p_drop_hidden=0.0):\n",
    "    l_1 = T.nnet.relu(conv2d(X, wc, border_mode='valid'))\n",
    "    l_1 = l_1.reshape((-1, 256))\n",
    "#     l_1 = dropout(l_1, p_drop_conv)\n",
    "\n",
    "#     l_2 = rectify(T.dot(layer_1, wh))\n",
    "#     l_2 = dropout(layer_2, p_drop_hidden)\n",
    "    \n",
    "    return l_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = T.ftensor4()# dims (mbs, n_channels, n_rows, n_cols)\n",
    "Y = T.fmatrix() # dims (mbs, o_depth)\n",
    "\n",
    "n_channels, n_rows, n_cols = 1, n_window, 21 # define protein \"image\" dimensions\n",
    "n_conv = 256 # features out of convolution\n",
    "h_depth = 50 # hidden layer depth\n",
    "o_depth = 6 # output depth\n",
    "\n",
    "# initialize weights for conv layer\n",
    "W_c = init_weights((n_conv, n_channels, n_rows, n_cols))\n",
    "\n",
    "# initial weight matrices\n",
    "W_uh = np.asarray(np.random.randn(n_conv, h_depth) * 0.001, dtype = theano.config.floatX)\n",
    "W_hh = np.asarray(np.random.randn(h_depth, h_depth) * 0.001, dtype = theano.config.floatX)\n",
    "W_hy = np.asarray(np.random.randn(h_depth, o_depth) * 0.001, dtype = theano.config.floatX)\n",
    "b_hh = np.zeros(h_depth, dtype=theano.config.floatX)\n",
    "b_hy = np.zeros(o_depth, dtype=theano.config.floatX)\n",
    "\n",
    "W_uh = theano.shared(W_uh, 'W_uh')\n",
    "W_hh = theano.shared(W_hh, 'W_hh')\n",
    "W_hy = theano.shared(W_hy, 'W_hy')\n",
    "b_hh = theano.shared(b_hh, 'b_hh')\n",
    "b_hy = theano.shared(b_hy, 'b_hy')\n",
    "\n",
    "# define new matrices \n",
    "Wr_uh = np.asarray(np.random.randn(n_conv, h_depth) * 0.001, dtype = theano.config.floatX)\n",
    "Wr_hh = np.asarray(np.random.randn(h_depth, h_depth) * 0.001, dtype = theano.config.floatX)\n",
    "Wz_uh = np.asarray(np.random.randn(n_conv, h_depth) * 0.001, dtype = theano.config.floatX)\n",
    "Wz_hh = np.asarray(np.random.randn(h_depth, h_depth) * 0.001, dtype = theano.config.floatX)\n",
    "\n",
    "Wr_uh = theano.shared(Wr_uh, 'Wr_uh')\n",
    "Wr_hh = theano.shared(Wr_hh, 'Wr_hh')\n",
    "Wz_uh = theano.shared(Wz_uh, 'Wz_uh')\n",
    "Wz_hh = theano.shared(Wz_hh, 'Wz_hh')\n",
    "\n",
    "h0_tm1 = theano.shared(np.zeros(h_depth, dtype=theano.config.floatX))\n",
    "\n",
    "# have conv_model outside of recurrent fn\n",
    "u = conv_model(X, W_c)\n",
    "\n",
    "params = [W_c, W_hh, W_uh, W_hy, Wr_uh, Wr_hh, Wz_uh, Wz_hh, b_hh, b_hy]\n",
    "\n",
    "def recurrent_fn(u_t, h_tm1, W_hh, W_uh, W_hy, Wr_uh, Wr_hh, Wz_uh, Wz_hh, b_hh, b_hy):\n",
    "    \n",
    "    r_t = activ(T.dot(u_t, Wr_uh) + T.dot(h_tm1, Wr_hh))\n",
    "    z_t = activ(T.dot(u_t, Wz_uh) + T.dot(h_tm1, Wz_hh))\n",
    "    \n",
    "    h_tilda = activ(T.dot(u_t, W_uh) + r_t*T.dot(h_tm1, W_hh), f='tan')\n",
    "    \n",
    "    h_t = ((1 - z_t)*h_tm1) + (z_t*h_tilda) + b_hh\n",
    "    \n",
    "    # adding in softmax, for one hot coding \n",
    "    y_t = T.nnet.softmax(T.dot(h_t, W_hy) + b_hy)\n",
    "    \n",
    "    return h_t, y_t\n",
    "\n",
    "[h, y], _ = theano.scan(recurrent_fn, \n",
    "                       sequences = u,\n",
    "                       outputs_info = [h0_tm1, None],\n",
    "                       non_sequences = [W_hh, W_uh, W_hy, Wr_uh, Wr_hh, Wz_uh, Wz_hh, b_hh, b_hy])\n",
    "\n",
    "y = y.reshape((-1, 6))\n",
    "\n",
    "# for some reason, y is a (128, 128, 6) tensor ? ---- had to do with the h @ t-1\n",
    "\n",
    "cost = T.mean((Y - y)**2)\n",
    "# cost = T.mean(T.nnet.categorical_crossentropy(y, Y))\n",
    "\n",
    "update = RMSprop(cost, params) #lr=1e-7\n",
    "\n",
    "y_x = T.argmax(y, axis=1)\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=[cost, y], updates=update, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of training iterations to perform\n",
    "n_train = 101\n",
    "\n",
    "# mini-batch size --- MUCH improved from previous 128\n",
    "mbs = 3 \n",
    "\n",
    "costs = []\n",
    "\n",
    "# performing our training\n",
    "for i in xrange(n_train):\n",
    "    for start, end in zip(xrange(0, len(xTrain), mbs), \n",
    "                          xrange(mbs, len(xTrain), mbs)):\n",
    "        cost, yi = train(xTrain[start:end], yTrain[start:end])\n",
    "#         print i, 'training:', np.mean(np.argmax(yTrain, axis=1) == predict(xTrain))\n",
    "#         print i, 'test:', np.mean(np.argmax(yTest, axis=1) == predict(xTest))\n",
    "#         print '-'*50\n",
    "    print 'cost:', cost\n",
    "    print 'yi:', yi\n",
    "    print i, 'training:', np.mean(np.argmax(yTrain, axis=1) == predict(xTrain))\n",
    "    print i, 'test:', np.mean(np.argmax(yTest, axis=1) == predict(xTest))\n",
    "    print '-'*50\n",
    "    costs.append(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "* Simple Feed-Forward gets us ~ 65% accuracy\n",
    "* Adding convolution helps (maybe we should make this layer wider?)\n",
    "* Adding Recurrancy (may) help\n",
    "* After many, many hours trying to get CUDA up and running on my local computer, I found out It's not compatible ... \n",
    "* Training, not surprisingly, takes a long time\n",
    "    * need to get AWS cluster up and running for training on GPU\n",
    "    * should have used Keris for batch normalization ... \n",
    "* Watch out for vanishing gradients!\n",
    "    * ELU does a good job of quashing these!\n",
    "* An adaptive learning rate would likely help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Future Work**:\n",
    "* Get this running on an AWS EC2 Cluster with GPUs\n",
    "* Implement Batch Normalization with Keras\n",
    "* Flip the proteins around, to instantly DOUBLE our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
